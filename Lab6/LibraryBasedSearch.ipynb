{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Wyszukiwarka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plan:\n",
    "tremin: 20.12.2017\n",
    "1. Dictionary\n",
    "    - Stop words removed\n",
    "    - Stemming (Porter Stemmer, Porter Stemmer 2)\n",
    "    - Reduction (optional)\n",
    "2. Budowa BackOfWords (indeksowanie)\n",
    "    - documentTermMatrix (wektory słów dla każdego artykułu)\n",
    "    - Inverse Document Frequency (IDF(w) - przemnożenie kolumny słowa w w documentTermMatrix przez IDF(w)\n",
    "    - Normalizacja (sprowadzenie wektora dla każdego dokumentu do jednostkowego - przydatne przy danych o zróżnicowanej długości)\n",
    "3. Query\n",
    "    - Przekleństwo wymiaru\n",
    "    - iloczyn skalarny\n",
    "4. SVD (LRMA)\n",
    "    - biblioteka, która liczy pierwsze k wektorów \n",
    "    - biblioteka dla danych żadkich\n",
    "5. * Semantyka w nietrywialny sposób\n",
    "    - Latent semantic indexing\n",
    "    - Latent Dirichlet approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, snowball\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import csr_matrix, lil_matrix, diags\n",
    "from scipy.sparse.linalg import svds\n",
    "import scipy\n",
    "import itertools\n",
    "from math import log\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filename = \"data.tsv\"\n",
    "# filename = \"articles2.csv\"\n",
    "filename = 'PythonApp/buzzfeed.csv'\n",
    "stopwords_filename = \"stopwords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if filename == 'PythonApp/buzzfeed.csv':\n",
    "    column_name = 'article'\n",
    "    texts = pd.read_csv(filename)\n",
    "    texts = texts.fillna('')\n",
    "    texts['title'].add_suffix(' ')\n",
    "    texts[column_name] = texts['title'] + \" \" + texts['first_paragraph'] + \" \" + texts['text']\n",
    "elif filename == 'articles2.csv':\n",
    "    texts = pd.read_csv(filename)\n",
    "    column_name = 'Article'\n",
    "elif filename == 'data.tsv':\n",
    "    texts = pd.read_csv(filename, header=0, delimiter=\"\\t\")\n",
    "    column_name = 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44064, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(stopwords_filename, \"r\") as file:\n",
    "    stopwords = set(file.read().splitlines()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_words(tokens, ps, wnl):\n",
    "    for t in tokens:\n",
    "        t = t.lower()\n",
    "        t = wnl.lemmatize(t)\n",
    "        t = re.sub('[^a-z]', '', t)\n",
    "        t = ps.stem(t)\n",
    "        yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CustomVectorizer(TfidfVectorizer):\n",
    "    \"\"\"TfidfVectorizer is a CountVectorizer with IDF transformation and normalisation:\n",
    "        vectorizer = CustomVectorizer()\n",
    "        vectorizer.fit_transform(texts)\n",
    "        transformer = TfidfTransformer()\n",
    "        tfidf = transformer.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stop_words='english'):\n",
    "        super(CustomVectorizer, self).__init__(stop_words=stop_words)\n",
    "#         ps = PorterStemmer()\n",
    "        self.ps = snowball.EnglishStemmer()\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super(CustomVectorizer, self).build_tokenizer()\n",
    "        return lambda doc: list(parse_words(tokenize(doc), self.ps, self.wnl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CustomVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "texts = texts.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:37<00:00, 102.84it/s]\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vectorizer.fit_transform(tqdm(texts[column_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SVD AND LOW RANK APPROXIMATION FOR DATA MATRIX\n",
    "U, s, V = svds(bag_of_words)\n",
    "#print(U.shape, V.shape, s.shape)\n",
    "\n",
    "approx = 30\n",
    "lra = len(s)*approx//100\n",
    "s[len(s) - lra:] = [0] * lra\n",
    "\n",
    "S = diags(s)\n",
    "\n",
    "bag_of_words_svd = U @ (S @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_sparse_csr('PythonApp/bag_of_words', bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('PythonApp/bag_of_words_svd', bag_of_words_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PythonApp/vectorizer.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, 'PythonApp/vectorizer.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_non_zero(bag_of_words):\n",
    "    if type(bag_of_words) == scipy.sparse.csr.csr_matrix:\n",
    "        return bag_of_words.count_nonzero()\n",
    "    else:\n",
    "        return np.count_nonzero(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_best_result(query, bag_of_words, k=10):\n",
    "    query_vec = vectorizer.transform([query])[0]\n",
    "    query_length = query_vec.count_nonzero()\n",
    "    number_of_docs = len(texts)\n",
    "    matches = {i: 0 for i in range(number_of_docs)}\n",
    "    for i in tqdm(range(number_of_docs)):\n",
    "        matches[i] = query_vec.multiply(bag_of_words[i]).sum()/(query_length * count_non_zero(bag_of_words[i]))\n",
    "#         matches[i] = [word * backOfWords[i,j] for j,word in enumerate(query_vec.nonzero()[1])][0].sum()/(query_length * backOfWords[i].count_nonzero())\n",
    "    return list(dict(sorted(matches.items(), key=lambda x: x[1], reverse=True)))[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_urls(best_results):\n",
    "    best_results = list(map(lambda x: texts['url'][x], best_results))\n",
    "    for i, result in enumerate(best_results):\n",
    "        print(i, ': ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6589/10000 [00:04<00:02, 1594.79it/s]/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 10000/10000 [00:06<00:00, 1565.07it/s]\n"
     ]
    }
   ],
   "source": [
    "best_results = get_best_result(\"Trump becomes the president\", bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6432, 2438, 1176, 1875, 7668, 3015, 6877, 1054, 3591, 5691]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  https://www.buzzfeed.com/sophmason/how-donald-is-your-trump-2t6pk\n",
      "1 :  https://www.buzzfeed.com/buzzfeednews/inauguration-day-emoji\n",
      "2 :  https://www.buzzfeed.com/kristimreed/learn-more-about-president-elect-trump-2ra6b\n",
      "3 :  https://www.buzzfeed.com/wooishgurl7/who-said-it-donald-trump-or-michael-scott-2g7qh\n",
      "4 :  https://www.buzzfeed.com/kerihw/you-know-what-uranium-is-right-nwsm\n",
      "5 :  https://www.buzzfeed.com/trvsndvl/do-you-know-the-real-donald-trump-2rhoy\n",
      "6 :  https://www.buzzfeed.com/deenazaidi/immigration-marine-le-pen-and-the-trump-connecti-2hg33\n",
      "7 :  https://www.buzzfeed.com/csdoingthings/trump-your-cat-40-cats-with-trump-hair-2rsa2\n",
      "8 :  https://www.buzzfeed.com/ferneine/states-of-the-trump-lqro\n",
      "9 :  https://www.buzzfeed.com/leonardos415b01eb6/i-was-inspired-by-trump-success-2t2br\n"
     ]
    }
   ],
   "source": [
    "print_urls(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2039.23it/s]\n"
     ]
    }
   ],
   "source": [
    "best_results = get_best_result(\"Trump becomes the president\", bag_of_words_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1583, 7746, 6432, 3894, 7642, 7915, 4084, 5695, 502, 8181]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  https://www.buzzfeed.com/annehelenpetersen/why-donald-trump-didnt-get-elected-the-first-time-around\n",
      "1 :  https://www.buzzfeed.com/jimwaterson/british-mp-says-uk-is-pimping-out-the-queen-for-donald-trump\n",
      "2 :  https://www.buzzfeed.com/sophmason/how-donald-is-your-trump-2t6pk\n",
      "3 :  https://www.buzzfeed.com/jimwaterson/theresa-may-won-trump-over-but-the-special-relationship-is-n\n",
      "4 :  https://www.buzzfeed.com/buzzfeednews/whats-going-on-around-the-world-today-feb-17-17\n",
      "5 :  https://www.buzzfeed.com/tomnamako/donald-trump-presser-media\n",
      "6 :  https://www.buzzfeed.com/maryanngeorgantopoulos/trump-wall-and-immigration-executive-orders\n",
      "7 :  https://www.buzzfeed.com/tariniparti/trump-world-including-steve-bannon-is-already-looking-at-the\n",
      "8 :  https://www.buzzfeed.com/buzzfeednews/whats-going-on-around-the-world-today-jan-12-17\n",
      "9 :  https://www.buzzfeed.com/emmaloop/lindsey-graham-says-he-will-look-into-trumps-wiretapping-cla\n"
     ]
    }
   ],
   "source": [
    "print_urls(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
